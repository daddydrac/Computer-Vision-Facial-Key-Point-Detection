{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n",
      "True\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n",
      "torch.float32\n",
      "cpu\n",
      "torch.strided\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.cuda as t\n",
    "import cupy as cu\n",
    "import numpy as np\n",
    "\n",
    "# Check if GPU is avail\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Support both CPU and GPU, when avail\n",
    "\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "  cu = cu\n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "  cu = np\n",
    "\n",
    "device = torch.device(dev)\n",
    "\n",
    "def gpu(t):\n",
    "    return t.to(device)\n",
    "\n",
    "\n",
    "gpu_cpu_test = gpu(torch.zeros(4,3))\n",
    "print(gpu_cpu_test)\n",
    "\n",
    "# Not piped to gpu\n",
    "t = torch.Tensor()\n",
    "\n",
    "# uniform number type for tensor\n",
    "print(t.dtype)\n",
    "\n",
    "# gpu or cpu?\n",
    "print(t.device)\n",
    "\n",
    "# Strided is default for how tensors are laid out in mem\n",
    "print(t.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6., 0., 0., 0., 0., 0.], device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#NVIDIA GPU Computing Tips with code example: \n",
    "When working with #cupy and #pytorch, you might have to do a \n",
    "couple things diff to turn a #numpy / cupy array into a tensor. \n",
    "First you need to copy the numpy (cupy )array, this will \n",
    "allocate new memory for numpy array . This is to prevent  \n",
    "negative strides within Ndarray which are  the number of \n",
    "locations in memory between beginnings of successive array elements. \n",
    "Next, we flip it with the Axis in the array, which  \n",
    "tells which entries are reversed. \n",
    "Lastly, we can finally convert the copied array to a tensor. \n",
    "dtypes are data type enforcement and cuda:0 is piping data to the \n",
    "GPU device which has an index of 0. This provides 7-9x speed up on \n",
    "processing in most scenarios for computer vision, and 20x speed up \n",
    "for analytics/non-machine vision applications like NLP. \n",
    "The following solution performs near 100% of the \n",
    "operations on the GPU:\n",
    "'''\n",
    "\n",
    "cupy_gpu = torch.tensor(\n",
    "    cu.flip(cu.copy(\n",
    "        cu.array([1,2,3,4,5,6])),\n",
    "            axis=0),\n",
    "            dtype=torch.float16, \n",
    "            device=dev\n",
    ")\n",
    "\n",
    "print(cupy_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "# CPU Bound Op\n",
    "numpy_cpu = np.arange(15).reshape(3, 5)\n",
    "print(numpy_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
